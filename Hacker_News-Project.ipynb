{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "You can find the data set here, but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First step:\n",
    "- read the file: hacker_news.csv\n",
    "- Display first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "open_file = open(\"HN_posts_year_to_Sep_26_2016.csv\")\n",
    "read_file = reader(open_file)\n",
    "\n",
    "hn = list(read_file)\n",
    "\n",
    "print(hn[0])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Steps\n",
    "- Create a list only with the header\n",
    "- create a list with all the data without the header\n",
    "- create a function to explore the dataset, print lines and display the total of rows and columns\n",
    "- Print the first 5 lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "\n",
      "\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      " * Number of rows: 293119\n",
      " * Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "# 1 - Dataset's header\n",
    "hn_header = hn[0]\n",
    "# 2 - dataset without header\n",
    "hn_dataset = hn[1:]\n",
    "# 3 - Function to explore the data\n",
    "\n",
    "def explore_dataset(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('\\n------------------------------------------------------')\n",
    "        print(' * Number of rows:', len(dataset))\n",
    "        print(' * Number of columns:', len(dataset[0]))\n",
    "        \n",
    "explore_dataset(hn_dataset, 0 , 5, True)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now that we've removed the headers from hn, we're ready to filter our data. Since we're only concerned with post titles beginning with Ask HN or Show HN, we'll create new lists of lists containing just the data for those titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Numbers of the ASK HN 9139\n",
      "* Numbers of the SHOW HN 10158\n",
      "* Numbers of OTHERS 273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for posts in hn_dataset:\n",
    "    title = posts[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(posts) \n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(posts)\n",
    "    else:\n",
    "        other_posts.append(posts)\n",
    "        \n",
    "print(\"* Numbers of the ASK HN\", len(ask_posts))\n",
    "print(\"* Numbers of the SHOW HN\", len(show_posts))\n",
    "print(\"* Numbers of OTHERS\", len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Explorer the new lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "--Some pots starting with the \"Ask hn\":--------------------------------------------------------------\n",
      "[['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53'], ['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17'], ['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57'], ['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48'], ['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']]\n",
      "\n",
      "--Some pots starting with the \"Show hn\":-------------------------------------------------------------\n",
      "[['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36'], ['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01'], ['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44'], ['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17'], ['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']]\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('\\n-----------------------------------------------------------------------------------------------------')\n",
    "print('\\n--Some pots starting with the \"Ask hn\":--------------------------------------------------------------')\n",
    "print(ask_posts[:5])  \n",
    "print('\\n--Some pots starting with the \"Show hn\":-------------------------------------------------------------')\n",
    "print(show_posts[:5])  \n",
    "print('\\n-----------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* The average of post with ASK HN 45695.0\n",
      "* The average of post with SHOW HN 1015800.0\n"
     ]
    }
   ],
   "source": [
    "for row in ask_posts:\n",
    "    total_ask_comments = 0\n",
    "    number_comments = int(row[4])\n",
    "    total_ask_comments += number_comments\n",
    "    \n",
    "avg_ask_comments = (len(ask_posts) / total_ask_comments) * 100\n",
    "print(\"* The average of post with ASK HN\", avg_ask_comments) \n",
    "\n",
    "for row in show_posts:\n",
    "    total_ask_comments = 0\n",
    "    number_comments = int(row[4])\n",
    "    total_ask_comments += number_comments\n",
    "    \n",
    "avg_ask_comments = (len(show_posts) / total_ask_comments) * 100\n",
    "print(\"* The average of post with SHOW HN\", avg_ask_comments) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    " 1 Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    " 2 Calculate the average number of comments ask posts receive by hour created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 2996, '01': 2089, '22': 3372, '21': 4500, '19': 3954, '17': 5547, '15': 18525, '14': 4972, '13': 7245, '11': 2797, '10': 3013, '09': 1477, '07': 1585, '03': 2154, '23': 2297, '20': 4462, '16': 4466, '08': 2362, '00': 2277, '18': 4877, '12': 4234, '04': 2360, '06': 1587, '05': 1838}\n",
      "\n",
      "\n",
      "{'02': 269, '01': 282, '22': 383, '21': 518, '19': 552, '17': 587, '15': 646, '14': 513, '13': 444, '11': 312, '10': 282, '09': 222, '07': 226, '03': 271, '23': 343, '20': 510, '16': 579, '08': 257, '00': 301, '18': 614, '12': 342, '04': 243, '06': 234, '05': 209}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    number_comments = int(row[4])\n",
    "    data_and_time = row[6]\n",
    "#    append to the list the two variables\n",
    "    result_list.append([data_and_time, number_comments])\n",
    "                                               \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    # take the datetime\n",
    "    date = row[0]\n",
    "    # take the number of comments\n",
    "    comment = row[1]\n",
    "    # Use the datetime.strftime() method to select just the hour from the datetime object.\n",
    "    time = dt.datetime.strptime(date, date_format).strftime('%H')\n",
    "\n",
    "    if time not in counts_by_hour:\n",
    "        counts_by_hour[time] = 1\n",
    "        comments_by_hour[time] = comment\n",
    "    else:\n",
    "        counts_by_hour[time] += 1\n",
    "        comments_by_hour[time] += comment\n",
    "        \n",
    "print(comments_by_hour)\n",
    "print('\\n')\n",
    "print(counts_by_hour)\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* calculate the average number of comments per post for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['02', 11.137546468401487],\n",
       " ['01', 7.407801418439717],\n",
       " ['22', 8.804177545691905],\n",
       " ['21', 8.687258687258687],\n",
       " ['19', 7.163043478260869],\n",
       " ['17', 9.449744463373083],\n",
       " ['15', 28.676470588235293],\n",
       " ['14', 9.692007797270955],\n",
       " ['13', 16.31756756756757],\n",
       " ['11', 8.96474358974359],\n",
       " ['10', 10.684397163120567],\n",
       " ['09', 6.653153153153153],\n",
       " ['07', 7.013274336283186],\n",
       " ['03', 7.948339483394834],\n",
       " ['23', 6.696793002915452],\n",
       " ['20', 8.749019607843136],\n",
       " ['16', 7.713298791018998],\n",
       " ['08', 9.190661478599221],\n",
       " ['00', 7.5647840531561465],\n",
       " ['18', 7.94299674267101],\n",
       " ['12', 12.380116959064328],\n",
       " ['04', 9.7119341563786],\n",
       " ['06', 6.782051282051282],\n",
       " ['05', 8.794258373205741]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hours = []\n",
    "\n",
    "for hours in comments_by_hour:\n",
    "    avg_by_hours.append([hours, comments_by_hour[hours] / counts_by_hour[hours]])\n",
    "\n",
    "avg_by_hours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read.\n",
    "### Calculating the Average Number of Comments for Ask HN Posts by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.137546468401487, '02'], [7.407801418439717, '01'], [8.804177545691905, '22'], [8.687258687258687, '21'], [7.163043478260869, '19'], [9.449744463373083, '17'], [28.676470588235293, '15'], [9.692007797270955, '14'], [16.31756756756757, '13'], [8.96474358974359, '11'], [10.684397163120567, '10'], [6.653153153153153, '09'], [7.013274336283186, '07'], [7.948339483394834, '03'], [6.696793002915452, '23'], [8.749019607843136, '20'], [7.713298791018998, '16'], [9.190661478599221, '08'], [7.5647840531561465, '00'], [7.94299674267101, '18'], [12.380116959064328, '12'], [9.7119341563786, '04'], [6.782051282051282, '06'], [8.794258373205741, '05']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hours:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the sorted() function to sort swap_avg_by_hour in descending order. Since the first column of this list is the average number of comments, sorting the list will sort by the average number of comments.\n",
    "\n",
    " - Set the reverse argument to True, so that the highest value in the first column appears first in the list.\n",
    " - Assign the result to sorted_swap.\n",
    "\n",
    "\n",
    "### Sorting and Printing Values from a List of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28.676470588235293, '15'],\n",
       " [16.31756756756757, '13'],\n",
       " [12.380116959064328, '12'],\n",
       " [11.137546468401487, '02'],\n",
       " [10.684397163120567, '10'],\n",
       " [9.7119341563786, '04'],\n",
       " [9.692007797270955, '14'],\n",
       " [9.449744463373083, '17'],\n",
       " [9.190661478599221, '08'],\n",
       " [8.96474358974359, '11'],\n",
       " [8.804177545691905, '22'],\n",
       " [8.794258373205741, '05'],\n",
       " [8.749019607843136, '20'],\n",
       " [8.687258687258687, '21'],\n",
       " [7.948339483394834, '03'],\n",
       " [7.94299674267101, '18'],\n",
       " [7.713298791018998, '16'],\n",
       " [7.5647840531561465, '00'],\n",
       " [7.407801418439717, '01'],\n",
       " [7.163043478260869, '19'],\n",
       " [7.013274336283186, '07'],\n",
       " [6.782051282051282, '06'],\n",
       " [6.696793002915452, '23'],\n",
       " [6.653153153153153, '09']]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_sorted = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "swap_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sort the values and print the the 5 hours with the highest average comments.\n",
    "* Arguments in the print \"{}\", arg1\n",
    "  - Argument_1 in the print is the time, identify by \"{}\"\n",
    "     - format the hours format()\n",
    "       - use: datetime.strptime() to especify the atual format \"%H\" and use strftime() to give a new format \"%H:%M\"\n",
    "  - Argument_2 in the print is the avg, identify by the formt {:.2f}\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments\n",
      "In hour: 15:00, the average comments per post is 28.68 \n",
      "In hour: 13:00, the average comments per post is 16.32 \n",
      "In hour: 12:00, the average comments per post is 12.38 \n",
      "In hour: 02:00, the average comments per post is 11.14 \n",
      "In hour: 10:00, the average comments per post is 10.68 \n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for 'Ask HN' Comments\")\n",
    "#Loop through each average and each hour (in this order) in the first five lists of sorted_swap.\n",
    "for avg, hr in swap_sorted[:5]:\n",
    "# Take the hours in the first argument {} that is in '%H' format exemple '15' \n",
    "#to transform using strftime to a new format \"%H:%M\" so '15:00'\n",
    "    print(\"In hour: {}, the average comments per post is {:.2f} \"\n",
    "          \n",
    "          .format(dt.datetime.strptime(hr, \"%H\").strftime(\"%H:%M\"), avg)\n",
    "         \n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour that receives the most comments per post on average is 15:00, with an average of 38.59 comments per post. There's an increase in the number of comments between the hours with the highest and second highest average number of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Conclusion\n",
    "\n",
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est).\n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, ask posts received more comments on average and ask posts created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est) received the most comments on average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
